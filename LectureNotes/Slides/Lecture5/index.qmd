---
title: "Lecture 5"
author: Julia Schedler
format: 
  revealjs: 
    code-fold: show
slide-number: true
execute: 
  eval: false
scrollable: true
filters: 
  - timer #need to have _extensions/produnis/timer in directory
---

## Link to template

::: hidden
$$
\newcommand\E{{\mathbb{E}}}
$$
:::

::: {.callout-note collapse="true" appearance="simple" icon="false"}
## Link to Notes Template

[Lecture5Template.qmd](ActivityTemplates/Lecture5Template.qmd)
:::

## Last time

-   Trend Stationarity model
-   Salmon price example
-   Simulating a time series to understand the autocovariance function

## Today

-   Time series at ENVR Conference
-   Detrending
-   Activities
-   Differencing

## A look ahead {.smaller}

-   Weeks 1-2: terminology of time series models, working with various R functions relating to time series (Chapters 1-2)
-   **Week 3: Trends, trends, trends (smoothing) (Chapters 2-3 in Shumway and Stoffer, Ch 8 in FPP)**
-   Week 4: Time series regression (trends that depend on predictor variables), Forecasting (Chapter 5 and 7 in FPP)
-   Week 5: Time series data science process, and midterm (Chapter 5 in FPP, various parts in Shumway and Stoffer)
-   Week 6: Partial correlation and ARMA models (Chapter 4 in Shumway and Stoffer)
-   Week 7: ARIMA models (what they are, when to use them, and how to know if yours is trash) (Chapter 4 in Shumway and Stoffer, Chapter 9 in FPP)
-   Week 8: Cross-correlation and Multiple time series (Ch 2, Ch 3 in Shumway and Stoffer)
-   Week 9: Wiggle room/class choice
-   Week 10: Wiggle room/class choice

# Time series at the ENVR Conference

## Is a "trend" necessarily linear?

::: incremental
-   Oh no, I have to talk to the intimidating experts
-   The very first talk: "A trend doesn't have to be linear"- Robert Lund
-   The penultimate talk: "seasonal trend"
:::

Conclusion:

::: incremental
-   Nope! Seems like "trend" = "mean function"
:::

## [Lots of examples of vocab we've learned...]{.r-fit-text}

## Notes on Robert Lund's Talk

![](../../images/IMG_0625.jpg)

## Notes on Robert Lund's Talk

![](../../images/IMG_0626.jpg)

## Notes from Matthias Katzfuss's talk

![](../../images/IMG_0621.jpg)

## Notes from Dan Cooley's talk

![Math anxiety rating: 70](../../images/IMG_0622.jpg)

## Notes from Dan Cooley's talk

![](../../images/IMG_0618.jpg)

# Detrending

## Detrending {.smaller}

If a process is trend stationary (nonstationary in the mean, but stationary in the variance), can we just subtract off the trend and get back a stationary time series?

Sometimes (assuming we are able to estimate it), and that's called **detrending**.

## Goal:

Assuming trend stationarity ($x_t = \mu_t + y_t$, where $y_t$ is stationary), find an estimate $\widehat{\mu}_t$ and compute

$$
\begin{align}
\widehat{y_t} &= x_t - \widehat{\mu_t}\\
\text{Estimated Stationary process} &= \text{Data - trend estimate}
\end{align}
$$ Note: Does $y_t$ remind you of anything from regression?

## Example: Subtracting off the trend {.smaller}

::: columns
::: {.column width="30%"}
-   Dark yellow line: the trend estimate
-   black: The observed data
-   shaded region: 95% confidence bands on trend estimates.

Can we make the time series stationary by subtracting off the trend?
:::

::: {.column width="70%"}
![](../../images/TREND.png)
:::
:::

## Example: Subtracting off the trend

Does this time series appear stationary? In the mean, yes.

![](../../images/DIFF.png)

## Example: Subtracting off the trend

Have we captured the temporal structure in the time series? Yes (note: we will learn about ACF hypothesis tests/p-values during the "time series data analysis process")

![](../../images/acf.png)

## Aside: managing a time series project code base

-   I manage the [GitHub for Houston Wastewater Epidemiology](https://github.com/hou-wastewater-epi-org/online_trend_estimation/)
-   Check out the "issues"
-   Section 1: Demo adding new issue ("basic" time series methods)
-   Section 2: Demo adding new issue (link to definition of online estimation)

## [Activity 1: Detrending a commodity (Example 3.7)]{.r-fit-text} {.smaller}

-   Given the code to generate the plot with the trend line, how would you view the equation of the trend line?
-   Visualize the de-trended series. Does it appear stationary?
-   Compute the acf of the salmon series and the detrended series. What do you notice?

::: {#Activity1 .timer seconds="300" starton="interaction"}
:::

## Activity 1 Solutions {.smaller}

-   Given the code to generate the plot with the trend line, how would you view the equation of the trend line?

```{r}
#| eval: true
library(astsa)
fit <- lm(salmon~time(salmon), na.action=NULL)
tsplot(salmon, col=4, ylab="USD per KG", main="Salmon Export Price")
abline(fit)

summary(fit)
```

-   Visualize the de-trended series. Does it appear stationary?

```{r}
#| eval: true
tsplot(resid(fit), main="detrended salmon price")
tsplot(salmon- fit$fitted.values)
```

-   Compute the acf of the salmon series and the detrended series. What do you notice?

```{r}
#| eval: true 

## two functions to use
par(mfrow=c(2,1)) # plot their ACFs
acf(salmon)
acf(resid(fit))

acf1(salmon)
acf1(resid(fit), 48, main="detrended salmon price")
```

## [Activity 2: "assuming we are able to estimate it"]{.r-fit-text}

::: columns
::: {.column width="50%"}
-   Look at pages 37-41 of the textbook
-   what is "it" in this context? (what are we estimating?)
-   If this is review, where did you first see these ideas?
-   Put a dot on the math anxiety rating distribution on the back board
:::

::: column
::: {#Activity2 .timer seconds="300" starton="interaction"}
:::
:::
:::

## [Activity 2]{.r-fit-text}[Solutions]{style="color:green;"}: "assuming we are able to estimate it" {.smaller}

-   Look at pages 37-41 of the textbook âœ…
-   what is "it" in this context? (what are we estimating?)

[The trend ($\beta_0$ and $\beta_1$), variance of the errors ($\sigma^2_w$). The]{style="color:green;"}

-   How are the estimates derived?

[Optimization (calculus)]{style="color:green;"}

-   If this is review, where did you first see these ideas?

[You may have seen this in Regression or Stat 426 (estimation and sampling theory), or Advanced Econometrics]{style="color:green;"}

-   Put a dot on the math anxiety rating distribution on the back board. Color the dot based on whether you seen the math/ideas before.

# Differencing

## Motivation/model {.smaller}

Consider the trend stationary model ($y_t$ is stationary). $$
x_t = \mu_t + y_t
$$ We saw how to estimate a *fixed* trend using a linear regression for the mean ($\mu_t = \beta_0 + \beta_1t$)

We then subtract off the estimate of the trend (detrend), $\widehat{\mu_t}$ so that we are working with a stationary time series:

$$
\widehat{y_t} = x_t - \widehat{\mu_t}
$$

What if the trend was not fixed? (dependent on $t$ beyond just "$t$ as a constant")

## A stochastic trend model

Change the model for the mean to incorporate a stochastic component (random walk with drift):

$$
\mu_t = \delta + \mu_{t-1} + w_t
$$ Where $w_t$ is white noise independent of $y_t$.

Is $\mu_t$ stationary? No (it's a random walk, nonstationary in both mean and covariance)

## How to "get back" to a stationary time series?

Since the stochastic component depends on just one past time point, consider the series $x_t - x_{t-1}$.

This series is called the **differenced** series and the process is called **differencing**.

## [Computing the difference series in terms of the (stochastic) trend model]{.r-fit-text}

$$
\begin{align}
x_{t} - x_{t-1} &= (\mu_t + y_t) - (\mu_{t-1} + y_{t-1})\\
&= (\delta + \mu_{t-1} + w_t + y_t) - (\mu_{t-1} - y_{t-1})\\
& = \delta + w_t + y_t - y_{t-1}
\end{align}
$$ Need to compute mean function $\E(x_t - x_{t-1}$ and autocovariance function $cov(x_t - x_{t-1}, x_s- x_{s-1})$ and check if they do not depend on $t$ (mean) and just depend on the lag $h = s-t$.

...But the answer is we do get a stationary series!

## [Activity 3: Simulating a random walk and then differencing it]{.r-fit-text}

1.  Simulate a random walk with no drift and plot it.

```{r}
#| eval: false

# your code here (check lecture 1- visualizing a random walk)
```

2.  Use the `diff` function to difference the simulated series. Plot the result.

```{r}
#| eval: false

# your code here
```

3.  Does this series appear stationary? How do you know?
4.  Visualize the ACF of the differenced series. Does it look like white noise?

```{r}
#| eval: false

# your code here
```

## [Activity 3 Solutions: Simulating a random walk and then differencing it]{.r-fit-text}

1.  Simulate a random walk with no drift and plot it.

```{r}
#| eval: true
#| code-fold: show
## Simulate random walk with no drift
set.seed(24) # so you can reproduce the results
w  = rnorm(200, mean = 0, sd = 1)  ## Gaussian white noise
x  = cumsum(w)
tsplot(x, main="random walk", ylab="", col=4)
 clip(0, 200, 0, 80)
 abline(a=0, b=0, lty=2, col=4) # drift
```

## [Activity 3 Solutions: Simulating a random walk and then differencing it]{.r-fit-text}

2.  Use the `diff` function to difference the simulated series. Plot the result.

```{r}
#| eval: true
tsplot(diff(x))
```

3.  Does this series appear stationary? How do you know? [Looks like some pseudo-cyclic behavior, so no.]{style="color:green;"}

## [Activity 3 Solutions: Simulating a random walk and then differencing it]{.r-fit-text}

4.  Visualize the ACF of the differenced series. Does it look like white noise?

```{r}
acf(diff(x, lag = 1, diff = 1))
```

[No-- looks like it could be an AR(1)?]{style="color:green;"}

## [Activity 4: Differencing Salmon Prices]{.r-fit-text}

1.  Compute and plot the differenced salmon series.

```{r}
#| eval: false
# your code here
```

2.  Does the series appear stationary?
3.  Visualize the acf of the differenced series. Does it look like white noise?

```{r}
#| eval: true
# your code here

```

## [Activity 4 Solutions: Differencing Salmon Prices]{.r-fit-text}

1.  Compute and plot the differenced salmon series.

```{r}
#| eval: true
tsplot(diff(salmon))
```

2.  Does the series appear stationary?

[In the mean-- yes, maybe?-- maybe a pseudo-cyclic type pattern? We should check the ACF]{style="color:green;"}

3.  Visualize the acf of the differenced series. Does it look like white noise?

```{r}
#| eval: true
acf1(diff(salmon))
```

[The acf of the differenced series appears to have patterns indicating annual cycles.]{style="color:green;"}

## [Activity 5: Comparing Differencing and Detrending]{.r-fit-text}

Compare the Acfs of the differenced and detrended salmon series. What do you notice?

```{r}
#| eval: false
# your code here
```

## [Activity 5 Solutions: Comparing Differencing and Detrending]{.r-fit-text}

Compare the Acfs of the differenced and detrended salmon series. What do you notice?

```{r}
#| eval: true

par(mfrow = 2:1)
acf1(resid(fit))
acf1(diff(salmon))
```

[The detrended series and the differenced series both show cycles, but the structure of those cycles appears different.]{style="color:green;"}

## Next time: Smoothing

We've seen three explicity ways of modeling a trend (moving average (hw 1), and regression with time and random walk).

How else could we model a trend?

## Visual example:

```{r}
#| code-fold: show
tsplot(soi, col=4)
lines(ksmooth(time(soi), soi, "normal", bandwidth=1), lwd=2, col=6)
#par(fig = c(.65, 1, .75, 1), new = TRUE) # the insert
curve(dnorm, -3, 3,  xaxt='n', yaxt='n', ann=FALSE)
```
